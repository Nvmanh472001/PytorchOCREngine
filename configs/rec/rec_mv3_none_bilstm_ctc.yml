Global:
  device: gpu
  epoch_num: 72
  log_smooth_window: 20
  print_batch_step: 10
  output_dir: ./output/rec/rec_mv3_none_bilstm_ctc
  eval_epoch_step: [0, 1]
  cal_metric_during_train: true
  pretrained_model:
  checkpoints:
  use_tensorboard: false
  infer_mode: false
  infer_img: doc/imgs_words/en/word_1.png
  character_dict_path: &character_dict_path
  max_text_length: &max_text_length 25
  use_space_char: &use_space_char False


Export:
  export_dir:
  export_shape: [ 1, 3, 32, 100 ]
  dynamic_axes: [ 0, 2, 3 ]

Optimizer:
  name: Adam
  lr: 0.0005
  weight_decay: 0.0

LRScheduler:
  name: CosineAnnealingLR
  warmup_epoch: 0

Architecture:
  model_type: rec
  algorithm: CRNN
  Transform:
  Backbone:
    name: MobileNetV3
    scale: 0.5
    model_name: large
  Neck:
    name: SequenceEncoder
    encoder_type: rnn
    hidden_size: 96
  Head:
    name: CTCHead

Loss:
  name: CTCLoss

PostProcess:  
  name: CTCLabelDecode
  character_dict_path: *character_dict_path
  use_space_char: *use_space_char

Metric:
  name: RecMetric
  main_indicator: acc

Train:
  dataset:
    name: LMDBDataSet
    data_dir: ./train_data/data_lmdb_release/training/
    transforms:
      - DecodeImage: # load image
          img_mode: BGR
          channel_first: False
      - CTCLabelEncode: # Class handling label
      - RecResizeImg:
          image_shape: [3, 32, 100]
      - KeepKeys:
          keep_keys: ['image', 'label', 'length'] # dataloader will return list in this order
  loader:
    shuffle: False
    batch_size_per_card: 256
    drop_last: True
    num_workers: 8

Eval:
  dataset:
    name: LMDBDataSet
    data_dir: ./train_data/data_lmdb_release/validation/
    transforms:
      - DecodeImage: # load image
          img_mode: BGR
          channel_first: False
      - CTCLabelEncode: # Class handling label
      - RecResizeImg:
          image_shape: [3, 32, 100]
      - KeepKeys:
          keep_keys: ['image', 'label', 'length'] # dataloader will return list in this order
  loader:
    shuffle: False
    drop_last: False
    batch_size_per_card: 256
    num_workers: 4
